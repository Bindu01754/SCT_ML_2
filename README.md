Real-Time Hand Gesture Recognition Using Machine Learning

Project Description:

This project implements a real-time hand gesture recognition system that uses computer vision and machine learning to detect and classify hand gestures through a webcam feed. The system leverages MediaPipe for hand landmark extraction and a trained machine learning model for gesture classification. It demonstrates key steps in an applied computer vision pipeline, including landmark feature extraction, model integration, real-time inference, and visualization of predictions. The project provides practical exposure to building interactive AI systems for humanâ€“computer interaction.

Key Highlights:

Real-time webcam video capture using OpenCV
Hand landmark detection with MediaPipe
Feature extraction from 3D hand landmark coordinates
Gesture classification using trained ML model
On-screen prediction display
Recognition of predefined gestures (Palm, Fist, Thumbs Up, Peace)
Technologies & Libraries:

Python
OpenCV
MediaPipe
NumPy
Scikit-learn (for model training)
Pickle (model loading)
Workflow Overview:

Import required libraries
Load trained gesture classification model
Initialize MediaPipe hand detection module
Capture video stream from webcam
Detect hand landmarks in each frame
Extract landmark features for prediction
Classify gesture using trained model
Display gesture label on live video feed
Learning Outcomes:

Understanding real-time computer vision pipelines
Applying landmark-based feature extraction
Integrating trained ML models into live applications
Working with video streams and visual overlays
Building interactive AI-driven user interfaces
